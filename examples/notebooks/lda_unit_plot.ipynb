{
 "metadata": {
  "name": "",
  "signature": "sha256:3f0ec6ffbfb5b74237cc8084d15958d5348e346e647868e94575ec6b5e9712f9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from venture.venturemagics.ip_parallel import *\n",
      "from venture.venturemagics.reg_demo_utils import *\n",
      "from lda_utils import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# GEN DOCS FROM PRIOR\n",
      "  \n",
      "gen_params={'true_no_topics':4, 'size_vocab':40,\n",
      "            'no_docs':8, 'doc_length':30, \n",
      "            'alpha_t_prior':'.2', 'alpha_w_prior':'.2'}\n",
      "            \n",
      "generate_docs_out = generate_docs(gen_params)\n",
      "\n",
      "print_summary(generate_docs_out)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from venture import shortcuts\n",
      "from venture.unit import VentureUnit\n",
      "\n",
      "def rep_st(st,n): return  \" \".join([st]*n)\n",
      "\n",
      "class LDA(VentureUnit):\n",
      "    def makeAssumes(self):\n",
      "        self.assume(\"no_topics\", self.parameters['no_topics'])\n",
      "        self.assume(\"size_vocab\", self.parameters['size_vocab'])\n",
      "        self.assume(\"alpha_document_topic\", \"(gamma 1.0 2.0)\")\n",
      "        self.assume(\"alpha_topic_word\", \"(gamma 1.0 2.0)\")\n",
      "        self.assume(\"new_doc\",\"(lambda () (make_sym_dir_mult alpha_document_topic no_topics))\")\n",
      "        self.assume(\"documents\",\"(array (new_doc) (new_doc) (new_doc) (new_doc) (new_doc) (new_doc) (new_doc) (new_doc) )\" )\n",
      "\n",
      "        self.assume(\"new_topic\",\"(lambda () (make_sym_dir_mult alpha_topic_word size_vocab))\")\n",
      "        self.assume(\"topics\",\"(array (new_topic) (new_topic) (new_topic) (new_topic) )\" )\n",
      "        self.assume(\"get_word\", \"(mem (lambda (doc_ind word_ind) ((lookup topics ((lookup documents doc_ind) ))) ))\")\n",
      "    \n",
      "    def makeObserves(self):\n",
      "        D = self.parameters['no_documents']\n",
      "        N = self.parameters['doc_length']\n",
      "\n",
      "        for doc_ind in range(D):\n",
      "            for word_ind in range(N):\n",
      "                self.observe(\"(get_word %d %d)\" % (doc_ind,word_ind), \"atom<%d>\" % 0)\n",
      "        return\n",
      "\n",
      "# data generating model\n",
      "ripl = shortcuts.make_puma_church_prime_ripl()\n",
      "parameters = {'size_vocab': gen_params['size_vocab'], 'doc_length':gen_params['doc_length'], \n",
      "              'no_documents': gen_params['no_docs'], 'no_topics': gen_params['true_no_topics'] }   \n",
      "\n",
      "print 'parameters: ', parameters\n",
      "\n",
      "# observes\n",
      "all_docs = generate_docs_out['data_docs']\n",
      "data = [ el  for doc in all_docs for el in doc]; model = LDA(ripl, parameters)\n",
      "\n",
      "\n",
      "# venture unit: inference parameters\n",
      "no_sweeps = 30\n",
      "no_runs = 1\n",
      "history,_ = model.runFromConditional(no_sweeps,runs=no_runs,verbose=False,data=data)\n",
      "\n",
      "# venture unit: pull history\n",
      "no_topics = history.nameToSeries['no_topics'][0].values[0]\n",
      "unit_topics = history.nameToSeries['topics'][0].values\n",
      "unit_docs = history.nameToSeries['documents'][0].values\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# specify probe points from sequence of sweeps\n",
      "probes = [0,int(.5*no_sweeps),no_sweeps-1]\n",
      "\n",
      "probe_whist = []; # document_word_histograms inferred by model at probes\n",
      "unit_meankl_time=[]; unit_mean_diff_time=[]\n",
      "\n",
      "# compute histograms for inferred model at probe points\n",
      "for probe in probes:\n",
      "    print '\\n\\n probe no.: ',probe\n",
      "    \n",
      "    compare_inf_out= compare_inf(mk_p_ripl(),generate_docs_out,gen_params['true_no_topics'],collapse=1,\n",
      "                vunit=1, unit_topics=unit_topics[probe], unit_docs=unit_docs[probe])\n",
      "    \n",
      "    for key,val in compare_inf_out.items():\n",
      "        if not(type(val)==str) and not key.startswith('inf_ana'): print key,np.round(val,3)\n",
      "    \n",
      "    unit_meankl_time.append(np.mean( compare_inf_out['kls']) )\n",
      "    unit_mean_diff_time.append( compare_inf_out['mean/max_diff_doc_word_hist'][0] )\n",
      "    probe_whist.append( compare_inf_out['inf_ana_doc_word_hists'] )\n",
      "    \n",
      "true_emp_doc_word_hists = generate_docs_out['true_emp_doc_word_hists']\n",
      "\n",
      "unit_out = { 'inf_meankl_time':unit_meankl_time, 'inf_mean_diff_time':unit_mean_diff_time,\n",
      "       'true_emp_doc_word_hists': true_emp_doc_word_hists}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for probe in range(len(probes)):\n",
      "    cf_all_doc_hists(true_emp_doc_word_hists, probe_whist[probe],\n",
      "                 title1='True doc-word hists',title2='Inferred doc-word hists',\n",
      "                 bar=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cf_all_doc_hists(true_emp_doc_word_hists, probe_whist[-1],\n",
      "                 title1='True doc-word hists',title2='Inferred doc-word hists',\n",
      "                 bar=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}