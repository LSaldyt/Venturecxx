{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process Latent Variable Model (GP-LVM) for Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A wide variety of dimensionality reduction problems can be solved with the Gaussian Process Latent Variable Model (GP-LVM). For this, we simply use a GP to map from a latent variable to an observed one - sampling from the latent will serve as input for the GP.\n",
    "\n",
    "For reference see: http://jmlr.csail.mit.edu/papers/volume6/lawrence05a/lawrence05a.pdf\n",
    "\n",
    "\n",
    "### Scientific value:\n",
    "\n",
    "Coding this in practice is hard. We can show how to do this in Venture with\n",
    "only a few lines of code.\n",
    "\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "What currently does not work is gradient-based inference and multivariate input for GPs. For now, we only need to ensure that a GP can process input in  form of:\n",
    "\n",
    "- scalars;\n",
    "\n",
    "- 1- d arrays (to model vectors);\n",
    "\n",
    "- multi-dimensional arrays (to model matrices);\n",
    "\n",
    "a) **Multivariate input GPs.**\n",
    "\n",
    "In the future, we should allow GPs to cope with all kinds of input that can be used for a covariance function. For now, we only focus on the three above.\n",
    "\n",
    "=> Who is delivering this? Ulli with Taylor's help.\n",
    "\n",
    "\n",
    "b) **Gradient-based inference.** For now, gradient ascent inference is sufficient.\n",
    "\n",
    "=> Who is delivering this? Taylor with Ulli's help.\n",
    "\n",
    "### Goal: Dimensionality Reduction\n",
    "\n",
    "We want to perform dimensionality reduction using the Iris data set (Fig 1., below). Iris comes with four continous-valued features which we would like to map onto 2 latent components. According to this paper [Neal (2005)](http://jmlr.csail.mit.edu/papers/volume6/lawrence05a/lawrence05a.pdf) GP-LVM for likelihood optimization to find hyper-parameters in combination with independent GPs and linear kernels is equivalent to PCA. We therefore aim to produce a plot similar to Fig 3.\n",
    "\n",
    "Currently multivariate input for GPs is not implemented. We therefore deploy a \"fake\"-GP (see program_part_4, below) that stubbs the GP-LVM program. The aim is (i) to allow multivariate input to GPs to (ii) perform gradient ascent to make Fig. 2 similar to Fig 3 (produced with Scikit Learn). Fig 2 is currently stubbed due to the fake GP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from venture import shortcuts\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import codecs\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Iris dataset. This data set has four continuous valued variables and a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\")\n",
    "df.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.pairplot(df, hue=\"Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig. 1: Visualizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Venture Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ripl = shortcuts.make_lite_ripl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the 2-diemsional latent lariable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "program_part_1 = \"\"\"\n",
    "\n",
    "assume latent_component_1 = mem(\n",
    "    proc(data_index){\n",
    "        normal(0,10)\n",
    "        }\n",
    "    );\n",
    "        \n",
    "assume latent_component_2 = mem(\n",
    "    proc(data_index){\n",
    "        normal(0,10)\n",
    "        }\n",
    "    );\n",
    "        \n",
    "assume latent_variable = mem(\n",
    "            proc(data_index){\n",
    "                list(\n",
    "                   latent_component_1(data_index),\n",
    "                   latent_component_2(data_index)\n",
    "                )\n",
    "                }\n",
    "            );\n",
    "\"\"\"\n",
    "ripl.execute_program(program_part_1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "program_part_2 = \"\"\"\n",
    "assume tolerance_constant = 00000.1;\n",
    "\n",
    "// Indexed Hyper-parameters\n",
    "assume noise_sigma = mem(\n",
    "                        proc(gp_index){\n",
    "                            tag(\"noise\", gp_index, gamma(5,1))\n",
    "                        }\n",
    "                    );\n",
    "                    \n",
    "assume scale_factor = mem(\n",
    "                        proc(gp_index){\n",
    "                            tag(\"scale\", gp_index, gamma(5,1))\n",
    "                        }\n",
    "                    );\n",
    "                    \n",
    "assume offset = mem(\n",
    "                        proc(gp_index){\n",
    "                            tag(\"off\", gp_index, gamma(5,1))\n",
    "                        }\n",
    "                    );\n",
    "\"\"\"\n",
    "ripl.execute_program(program_part_2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "program_part_3= \"\"\"\n",
    "assume noise_kernel = proc(gp_index){\n",
    "    gp_cov_scale(\n",
    "            noise_sigma(gp_index),\n",
    "            gp_cov_delta(tolerance_constant)\n",
    "            )\n",
    "    };\n",
    "    \n",
    "assume linear_kernel = proc(gp_index){\n",
    "    gp_cov_scale(\n",
    "        scale_factor(gp_index),\n",
    "        gp_cov_linear(offset(gp_index))\n",
    "        )\n",
    "    };\n",
    "\n",
    "assume covariance_kernel = proc(gp_index){\n",
    "    gp_cov_sum(\n",
    "        linear_kernel(gp_index),\n",
    "        noise_kernel(gp_index)\n",
    "        )\n",
    "    };\n",
    "\n",
    "assume zero_mean_function =gp_mean_const(0.);\n",
    "\"\"\"\n",
    "ripl.execute_program(program_part_3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a `fake_gp`- which ignores input covariance function and mean function and outputs a sample from a multivariate normal where the length of the sample is determined by the input to `fake_gp`. We do this because currently, multivariate input breaks the GP implementation - thus we stub the actual gp ( `make_gp` ) to generate plots and results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "program_part_4 = \"\"\"\n",
    "assume fake_gp = proc(mean_function, covariance_function){\n",
    "    proc(x){\n",
    "        zeros = fill(size(lookup(x,0)), 0);\n",
    "        ones  = fill(size(lookup(x,0)), 1);\n",
    "        \n",
    "        multivariate_normal(zeros,diag_matrix(ones))    \n",
    "    }\n",
    "};\n",
    "\"\"\"\n",
    "ripl.execute_program(program_part_4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call 4 indepedent GPs that map from the 2 dimensional latent variable onto the observed output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "program_part_5 = \"\"\"\n",
    "// independent GPs for each observed dimension\n",
    "assume gp1 = fake_gp(zero_mean_function, covariance_kernel(1));\n",
    "assume gp2 = fake_gp(zero_mean_function, covariance_kernel(2));\n",
    "assume gp3 = fake_gp(zero_mean_function, covariance_kernel(3));\n",
    "assume gp4 = fake_gp(zero_mean_function, covariance_kernel(4));\n",
    "\"\"\"\n",
    "ripl.execute_program(program_part_5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(df.index)):\n",
    "    ripl.execute_program(\"observe gp1(array(latent_variable(%i))) = array(%d)\"  % (i,df.iloc[i][\"SepalLength\"]))\n",
    "    ripl.execute_program(\"observe gp2(array(latent_variable(%i))) = array(%d)\"  % (i,df.iloc[i][\"SepalWidth\"]))\n",
    "    ripl.execute_program(\"observe gp3(array(latent_variable(%i))) = array(%d)\"  % (i,df.iloc[i][\"PetalLength\"]))\n",
    "    ripl.execute_program(\"observe gp4(array(latent_variable(%i))) = array(%d)\"  % (i,df.iloc[i][\"PetalWidth\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ripl.infer(\"\"\"mh(default, one, 100)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we need to get to run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ripl.infer(\"grad_ascent(default, all, 0.05, 100, 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latent_sample1 = []\n",
    "latent_sample2 = []\n",
    "for i in range(len(df.index)):\n",
    "    current_latent_sample = ripl.sample(\"x(%i)\" % (i,))\n",
    "    latent_sample1.append(current_latent_sample[0])\n",
    "    latent_sample2.append(current_latent_sample[1])\n",
    "    \n",
    "latent_sample1 = np.array(latent_sample1)\n",
    "latent_sample2 = np.array(latent_sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Loading of Latent Components\n",
    "\n",
    "Below, we plot the two latent components and color datapoints according to their species (i.e. Iris name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(latent_sample1[np.array(df[\"Name\"]==\"Iris-virginica\")],latent_sample2[np.array(df[\"Name\"]==\"Iris-virginica\")], color=\"red\", label= \"Iris-virginica\")\n",
    "plt.scatter(latent_sample1[np.array(df[\"Name\"]==\"Iris-versicolor\")],latent_sample2[np.array(df[\"Name\"]==\"Iris-versicolor\")], color=\"green\", label= \"Iris-versicolor\")\n",
    "plt.scatter(latent_sample1[np.array(df[\"Name\"]==\"Iris-setosa\")],latent_sample2[np.array(df[\"Name\"]==\"Iris-setosa\")], color=\"blue\", label= \"Iris-setosa\")\n",
    "plt.xlabel(\"Latent Component 1\")\n",
    "plt.ylabel(\"Latent Component 2\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with SciKit learn (comparison)\n",
    "\n",
    "Below, we run a simple (out-of-the-box) PCA to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\")\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(np.array(df.drop(\"Name\", axis=1))) \n",
    "sk_latent = np.dot(np.array(df.drop(\"Name\", axis=1)),pca.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(sk_latent[:,0][np.array(df[\"Name\"]==\"Iris-virginica\")],sk_latent[:,1][np.array(df[\"Name\"]==\"Iris-virginica\")], color=\"red\", label= \"Iris-virginica\")\n",
    "plt.scatter(sk_latent[:,0][np.array(df[\"Name\"]==\"Iris-versicolor\")],sk_latent[:,1][np.array(df[\"Name\"]==\"Iris-versicolor\")], color=\"green\", label= \"Iris-versicolor\")\n",
    "plt.scatter(sk_latent[:,0][np.array(df[\"Name\"]==\"Iris-setosa\")],sk_latent[:,1][np.array(df[\"Name\"]==\"Iris-setosa\")], color=\"blue\", label= \"Iris-setosa\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.legend()\n",
    "#ax = sns.kdeplot(sk_latent[:,0][np.array(df[\"Name\"]==\"Iris-versicolor\")],sk_latent[:,1][np.array(df[\"Name\"]==\"Iris-versicolor\")], cmap=\"Greens\")\n",
    "#ax = sns.kdeplot(sk_latent[:,0][np.array(df[\"Name\"]==\"Iris-setosa\")],sk_latent[:,1][np.array(df[\"Name\"]==\"Iris-setosa\")], cmap=\"Blues\")\n",
    "#ax = sns.kdeplot(sk_latent[:,0][np.array(df[\"Name\"]==\"Iris-versicolor\")], latent_sample2[np.array(df[\"Name\"]==\"Iris-versicolor\")],  cmap=\"Greens\")\n",
    "#ax = sns.kdeplot(sk_latent[:,0][np.array(df[\"Name\"]==\"Iris-setosa\")], latent_sample2[np.array(df[\"Name\"]==\"Iris-setosa\")],  cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig. 2: Principal Component Analysis. We plot the 2 latent components and color by Iris species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
