{
 "metadata": {
  "name": "",
  "signature": "sha256:8958dee45c8a580e6ed2bc5d7f9db394739094044c0ef1044fb2f8bf8f7c316c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Curve-fitting in Venture"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from venture.venturemagics.ip_parallel import *\n",
      "from venture.venturemagics.reg_demo_utils import *\n",
      "r=make_puma_church_prime_ripl()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%venture r\n",
      "[clear]\n",
      "[assume w0 (normal 0 3) ]\n",
      "[assume w1 (normal 0 1) ]\n",
      "[assume w2 (normal 0 .3) ]\n",
      "[assume x_d (lambda () (normal 0 5))]\n",
      "[assume noise (gamma 2 1) ]\n",
      "[assume f (lambda (x) (+ w0 (* w1 x) (* w2 (* x x)) ) ) ]\n",
      "[assume y_x (lambda (x) (normal (f x) noise) ) ]\n",
      "[assume model_name (quote simple_quadratic)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# at any time, display all observes or assumes\n",
      "assumes = display_directives(r,'assume')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs=list(np.random.normal(3,.7,3)) + list(np.random.normal(-1,1.4,8)) # generate x values\n",
      "f = lambda x:-2*x\n",
      "y_x = lambda x: np.random.normal(f(x),.6)\n",
      "ys = [y_x(x) for x in xs]   # compute y values from x,f and Normal noise                                 \n",
      "fig,ax = plt.subplots(figsize=(3,3))\n",
      "ax.scatter(xs,ys)\n",
      "ax.set_xlim(-6,6); ax.set_ylim(-8,8)\n",
      "\n",
      "data = zip(xs,ys)\n",
      "data0,data1 = data[:6],data[6:]   # split the data set in two\n",
      "\n",
      "for i,(x,y) in enumerate(data0):\n",
      "    r.observe('(x_d)', '%f' % x ) \n",
      "    r.observe('(y_x %f)' % x , '%f' % y )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot prior conditional\n",
      "out=plot_conditional(r,data=data0,x_range=(-8,8),number_xs=30,number_reps=30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot posterior conditional after inference\n",
      "r.infer(1000)\n",
      "out=plot_conditional(r,data=data0,x_range=(-8,8),number_xs=30,number_reps=30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# how to make this kind of plot?\n",
      "\n",
      "# left plot: either extract params, or sample evaluations of f\n",
      "def my_plot_conditional(ripl,x_range=(-8,8),number_xs=30):\n",
      "    xr = np.linspace(x_range[0],x_range[1],number_xs)\n",
      "    f_xr = np.array([ripl.predict('(f %f)' %x,label='f%i'%i) for i,x in enumerate(xr) ])\n",
      "    [ripl.forget('f%i'%i) for i,x in enumerate(xr) ]\n",
      "\n",
      "    y_xr = [ripl.predict('(y_x %f)' %x,label='y%i'%i) for i,x in enumerate(xr) ]\n",
      "    [ripl.forget('y%i'%i) for i,x in enumerate(xr) ]\n",
      "    \n",
      "    fig,ax = plt.subplots(1,2,figsize=(4,2.5))\n",
      "    ax[0].plot(xr,f_xr) ## ax[0].plot(xr,f_l,xr,f_u)\n",
      "    ax[1].scatter(xr,y_xr) ##ax[1].plot(xr,y_mean,xr,y_l,xr,y_u)\n",
      "    return xr,f_xr\n",
      "\n",
      "out = my_plot_conditional(r,(-10,8),20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'f(x) = %.2f + %.2fx + %.2fx^2' % (r.sample('w0'),r.sample('w1'),r.sample('w2'))\n",
      "print 'y = N(f(x),%.2f)' % r.sample('noise')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# With single ripl, we don't get a good measure of posterior uncertainty after seeing just 5 points\n",
      "v=MRipl(10)\n",
      "v.execute_program(simple_quadratic_model)\n",
      "observe_xy(v,data0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# illustrate mapping functions across ripls (limiting to only 2 per engine)\n",
      "def sample_params(r):\n",
      "    return (r.sample('w0'),r.sample('w1'),r.sample('w2')), r.sample('noise') \n",
      "\n",
      "outs = v.map_proc(2,sample_params)\n",
      "for w,noise in outs:\n",
      "    print 'f(x) = %.2f + %.2fx + %.2fx^2' % w, '    y = N(f(x),%.2f)' % noise\n",
      "    print '-----'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# illustrate mapping with plotting function from above\n",
      "outs = v.map_proc(2,my_plot_conditional)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out=v.map_proc(4,plot_conditional,data=data0,x_range=(-8,8),number_xs=20,number_reps=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# with mripls, it's easy to plot an approximation of the predictive distribution\n",
      "# on y given X=x. we just need to sample y given X=x multiple times for each ripl\n",
      "# and combine samples. \n",
      "out=predictive(v,data=data0,x_range=(-8,8),number_xs=40,number_reps=40)\n",
      "\n",
      "#FIXME: plotting the curves that predictive users from plot_cond, but not predictive itself\n",
      "\n",
      "# note that because the prior on the quadratic parameters are normals \n",
      "# symmetric about 0, our predictive distribution is symmetric"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# we can now look at sample curves from our posterior:\n",
      "# curves are close to the points, but they generalize\n",
      "# differently\n",
      "v.infer(1000)\n",
      "out=v.map_proc(4, plot_conditional,data=data,x_range=(-6,6),number_xs=10,number_reps=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# information from all curves in our mripl\n",
      "# is combined in the posterior_conditional:\n",
      "# we see that our uncertainy increased \n",
      "# substantially as we move away from our data\n",
      "out = predictive(v,data=data,x_range=(-6,6),number_xs=20,number_reps=20)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print simple_fourier_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vf = MRipl(10)\n",
      "vf.execute_program(simple_fourier_model)\n",
      "observe_xy(vf,data=data)\n",
      "vf.infer(1000)\n",
      "out = vf.map_proc(4, plot_conditional, data=data, x_range=(-5,5),number_xs=20,number_reps=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vs = [v,vf]\n",
      "[display_logscores(r) for r in vs]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# simple example of model selection. we now have prior on the distribution\n",
      "# on x and we have a model that is a mixture of fourier and quadratic\n",
      "print x_model_t + quad_fourier_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v = MRipl(10)\n",
      "v.execute_program(x_model_t + quad_fourier_model)\n",
      "observe_xy(v,data=data)\n",
      "v.infer(500)\n",
      "out=v.map_proc(4, plot_conditional,data=data,x_range=(-5,5),number_xs=20, number_reps=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out=predictive(v,data=data,x_range=(-6,6),number_xs=20,number_reps=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}