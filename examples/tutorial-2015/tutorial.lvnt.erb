<% sample_size = 500 %>
<% if ENV['SMOKETEST'] then sample_size = 5 end %>
<% smaller_sample_size = [sample_size / 5, 5].max %>
<% refman_url = "http://probcomp.csail.mit.edu/venture/edge/reference/" %>

Getting Started
===============

Start a venture session by running

```
$ venture lite --lang venture_script
```

You can also run venture scripts by making a file with a `.vnts`
extension and running

```
$ venture lite -f script.vnts
```

N.B.: The [command line reference](<%= refman_url %>usage.html#standalone-invocation)
explains what's happening here and what other options Venture accepts.

Basics
======

Sample an expression

```church'
(uniform_continuous 0 1)
```

These are independent samples from the unit uniform distribution

```church'
(uniform_continuous 0 1)
```

We can introduce a variable:

```venture
define mu = expon(2)  // Exponential distribution with rate 2
```

whose value is a particular sample from that distribution:

```church'
mu
```

and we can sample further expressions conditioned on that value:

```church'
(normal mu 0.2)
```

Exercise: Convince yourself that, for any given `mu`, `(normal mu 0.2)`
is a different distribution from

```church'
(normal (expon 2) 0.2)
```

because the latter samples a new internal mu every time.

You can find the [list of distributions](<%= refman_url
%>modeling.html#built-in-procedures) (and deterministic functions)
available in Venture in the appropriate section of the [reference
manual](<%= refman_url %>).

Now clear your session (or quit and restart Venture) for the next
segment:

```venture
clear
```

Basic Modeling
==============

When we used `define` to make a `mu` variable in the previous
segment, that variable's value was fixed to a particular sample from
its generating distribution for the remainder of the program.

In order to make variables that we can learn things about by
observation and reasoning, we need to flag them as uncertain, using
`assume`:

```venture
assume x = normal(0, 1)
```

Now `x` is a normally distributed random variable, and its current
value is a sample from that distribution.

Assumed and defined variables live in separate namespaces in Venture,
so just a bare `x` gives an error:

```church'
x
```

To access the current value of an assumed variable, we use `sample`

```venture
sample x
```

Note that repeated access to `x` gives the same value each time:

```venture
sample x + x
```

That's what allows us to form models with conditional dependencies,
such as this extension:

```venture
assume y = normal(x, 1)
```

So, why is `assume` any more useful than `define`?  Models, unlike the
top level, allow us to register observations:

```venture
observe y = 2
```

Note: the values of `x` and `y` don't change --

```venture
sample x
```

```venture
sample y
```

 -- all we did was register an observation.

Now infer.

```venture
infer posterior
sample y
```

Now `y` obeys the observation, and `x` is a sample from the posterior
distribution `p(x|y=2)` defined by our assumptions and observations:

```venture
sample x
```

If we do no more inference, `x` doesn't change.

```venture
sample x
```

But we can compute a new posterior sample by running the posterior
inferrer again.

```venture
infer posterior
sample x
```

Better Inspection
=================

As a reminder, we were studying this model (you can skip this block if
you have your session from the last segment):

```venture
clear
assume x = normal(0, 1)
assume y = normal(x, 1)
observe y = 2
```

We can get samples from inference

```venture
infer posterior
sample x
```

but are they actually from the right distribution?  We could eyeball
it like this a bit more:

```venture
infer posterior
sample x
```

```venture
infer posterior
sample x
```

but that will get old quickly.

It's better to gather data programmatically, for example like this:

```venture
define data = run(accumulate_dataset(4, do(posterior, collect(x))))
```

If you really want to know what's going on in this expression you can
study the documentation of [do](<%= refman_url
%>inference.html#special-forms), [run](<%= refman_url
%>inference.html#run), and [accumulate_dataset](<%= refman_url
%>inference.html#accumulate_dataset).  The effect is to gather up the
values of `x` (and some metadata) over 4
iterations of the `posterior` inference command.

```church'
(print data)
```

Do those values of `x` look good?  The values look sane to me, but I
can't eyeball a table of numbers and tell whether they are distributed
properly.  Let's get more data and plot it:

```venture
define more_data = run(accumulate_dataset(<%= smaller_sample_size %>, do(posterior, collect(x))))
```

```church'
(plot 'h0 more_data)
```

That `h0` says "make a histogram of the zeroth collected data stream".
You will eventually want to study [the plot spec reference](<%= refman_url %>inference.html#plot),
because that explains how to plot any of the values or metadata collected in the dataset
on the x, y, or color axis of a plot.

Here's a version with more samples for better resolution:

```church'
(plot 'h0 (run (accumulate_dataset <%= sample_size %> (do posterior (collect x)))))
```

The analytical answer is a Gaussian with mean 1 and precision 2 (which
is standard deviation `1/sqrt(2)`), whose histogram looks like this:

![A Gaussian with a lot of samples](gauss_plot.png)

Exercise: How visually close can you get to this plot by increasing
the number of iterations (the <%= sample_size %>) in the above
expression?  Is inference working?  Are you satisfied with how fast it
is?

In the next segment, we will look at a few different inference
strategies, which give different speed-accuracy tradeoffs.

[Say somewhere: we start with the normal-normal model because it's
easy and has an analytic solution, but the Gaussian distribution is
actually a pretty good proxy for all probability problems: the mean is
like the "right answer", and the precision is like "how well or
precisely I know it", or conversely the variance is like "how much
slack I am willing to tolerate".]

Inference Choices
=================

Rejection sampling does not solve all problems
----------------------------------------------

`posterior` is rejection sampling -- likely to get slow.  In
particular, let's see what happens as we change the model to make the
problem harder.  First, have a look at what we have:

```venture
list_directives
```

[Note: The above output is presented in a prefix notation syntax that
represents how it actually parsed.]

Now we can use `forget` to remove the existing observation and replace
it with one where the datum is farther out.

```venture
forget 24
observe normal(x,1) = 4
```

The same solution still works

```venture
infer plotf(quote(h0), run(accumulate_dataset(<%= smaller_sample_size %>, do(posterior, collect(x)))))
```

but if you fiddle with the numbers here (the 4 and the <%= smaller_sample_size %>) you can
tell that more distant observations take longer to get samples for.
[Inference phenomenon: KL divergence between prior and posterior
measures problem difficulty; rejection sampling (which is the
algorithm the `posterior` command uses) is exponentially slow in the
KL gap it is trying to cross.]

Alternative for fiddling: Copy this to a file, say `exact.vnts`

```
assume x = normal(0,1)
observe normal(x,1) = 4
infer plotf(quote(h0), run(accumulate_dataset(<%= smaller_sample_size %>, do(posterior, collect(x)))))
```

and run it with

```
$ venture lite -f exact.vnts
```

while editing numbers to heart's content.

Importance Sampling with Resampling
-----------------------------------

A very common inference technique is importance sampling with
resampling.  It is:

- Draw some number of trials from the prior [or any proposal
  distribution of your choice]

- Weight them by the likelihood [or the ratio between the posterior
  and proposal probabilities]

- Select one at random in proportion to its weight [or more than one,
  but then they are not independent of each other]

Here's what a basic version of this looks like in Venture.  Make 10
particles

```venture
infer resample(10)
```

Reset them to the prior and weight by likelihood:

```venture
infer likelihood_weight()
```

Pick one

```venture
infer resample(1)
sample x
```

Here's the distribution that makes:

```venture
infer plotf(quote(h0), run(accumulate_dataset(<%= smaller_sample_size %>,
  do(resample(10),
     likelihood_weight(),
     resample(1),
     collect(x)))))
```

[Inference phenomenon: 10 trials do not solve this problem if the
observation is 4 sigma out from the prior.  On the plus side, 10
trials always take the same amount of time, regardless of how hard the
problem is; and for any given problem enough trials will solve it.
This is a time-accuracy tradeoff.  Feel free to paste this inference
program into a file and mess with the numbers to see what changes.
Try it slowly increasing the number of trials and see how the
distribution evolves toward the right answer.]

Basic Metropolis-Hastings Markov Chains
---------------------------------------

[TODO Fill in the storytelling here]

```venture
infer plotf(quote(h0), run(accumulate_dataset(<%= 4*sample_size %>, do(mh(default, one, 1), collect(x)))))
```

[See how the distribution evolves with more transitions]

```venture
infer plotf(quote(h0), run(accumulate_dataset(<%= sample_size %>, do(mh(default, one, 10), collect(x)))))
```

Optional Subunit: Custom M-H Proposals
--------------------------------------

[TODO Would want to abstract this code better for presentation; does
this even belong here?  Will the students wonder about custom
proposals at this stage?]

```church'
clear
```

```church'
[define gaussian_drift_mh
  (lambda (scope block sigma)
    (do (subproblem <- (select scope block))
        (values <- (get_current_values subproblem))
        (let ((move (lambda (value) (normal value sigma))) ; gaussian drift proposal kernel
              (new_values (mapv move values)))
          (do (rho_weight_and_rho_db <- (detach_for_proposal subproblem))
              (xi_weight <- (regen_with_proposal subproblem new_values))
              (let ((rho_weight (first rho_weight_and_rho_db))
                    (rho_db (rest rho_weight_and_rho_db)))
                (if (< (log (uniform_continuous 0 1)) (- xi_weight rho_weight))
                    pass                    ; accept
                    (do (detach subproblem) ; reject
                        (restore subproblem rho_db))))))))]

[assume x (normal 0 1)]
[observe (normal x 1) 10]
[infer
 (do (d <- (accumulate_dataset <%= smaller_sample_size %>
             (do (likelihood_weight)
                 ;; 50 seems to converge, for the datum being at 10
                 (repeat 10 (gaussian_drift_mh default all 1))
                 (collect x))))
     (plotf 'h0 d))]
```

More Modeling: Linear Regression
================================

Ok, one gaussian isn't that much fun: let's try varying the mean as
a function of the input, i.e. linear regression.

[Concepts: more elaborate models; functions; abstraction?; genericity
of built-in inference procedures]

```church'
clear
```

```church'
;; Prior on line parameters
[assume a (normal 0 7)]
[assume b (normal 0 4)]

;; Hypothesized linear relationship
[assume f (lambda (x) (+ a (* b x)))]

;; Prior for unknown noise level
[assume noise (gamma 1 1)]

;; Full data model: linear relationship with additive noise of
;; unknown but consistent magnitude
[assume obs_fun (lambda (x) (normal (f x) noise))]

;; A tiny data set
[observe (obs_fun 1) 2]
[observe (obs_fun 2) 2]

;; Scatter plot of parameters after some inferece
;; (independent short Markov chains)
[infer (plotf 'p0d1d (run (accumulate_dataset <%= smaller_sample_size %>
  (do reset_to_prior
      (mh default one 30)
      (collect a b)))))]
```

Topic: Understanding a model with visualization
===============================================

[Drop in pygame visualization code.  How much to explain vs black-box it?]

Elaboration: Outlier Detection
==============================

[TODO Go through this]

```church'
clear
```

```church'
;; Prior on line parameters
[assume a (normal 0 7)]
[assume b (normal 0 4)]

;; Hypothesized linear relationship
[assume f (lambda (x) (+ a (* b x)))]

;; Prior for unknown noise level
[assume noise (gamma 1 1)]

;; Prior on the outlier rate
[assume outlier_prob (uniform_continuous 0.01 0.3)]

;; Per-point outlier check
[assume is_outlier (mem (lambda (i)
  (flip outlier_prob)))]

;; Full data model: linear relationship with additive noise of unknown
;; but consistent magnitude, plus outlier detection with a broad
;; Gaussian outlier model.
[assume obs_fun
  (lambda (i x)
    (if (is_outlier i)
        (normal 0 100)
        (normal (f x) noise)))]

;; Data set
[observe (obs_fun 0 1) 0.5]
[observe (obs_fun 1 4) 0]
[observe (obs_fun 2 -3) 1]
[observe (obs_fun 3 -5) -1]

;; Scatter plot of parameters after some inferece
;; (independent short Markov chains)
[infer (plotf 'p0d1d (run (accumulate_dataset <%= smaller_sample_size %>
  (do reset_to_prior
      (mh default one 30)
      (collect a b)))))]
```

Using tags for inference control
================================

[TODO]

```church'
clear
```

```church'
;; Prior on line parameters
[assume a (tag 'param 'a (normal 0 7))]
[assume b (tag 'param 'b (normal 0 4))]

;; Hypothesized linear relationship
[assume f (lambda (x) (+ a (* b x)))]

;; Prior for unknown noise level
[assume noise (tag 'hyper 'noise (gamma 1 1))]

;; Prior on the outlier rate
[assume outlier_prob (tag 'hyper 'outlier_prob (uniform_continuous 0.01 0.3))]

;; Per-point outlier check
[assume is_outlier (mem (lambda (i)
  (tag 'outlier i
   (flip outlier_prob))))]

;; Full data model: linear relationship with additive noise of unknown
;; but consistent magnitude, plus outlier detection with a broad
;; Gaussian outlier model.
[assume obs_fun
  (lambda (i x)
    (if (is_outlier i)
        (normal 0 100)
        (normal (f x) noise)))]

;; Data set
[observe (obs_fun 0 1) 0.5]
[observe (obs_fun 1 4) 0]
[observe (obs_fun 2 -3) 1]
[observe (obs_fun 3 -5) -1]

;; Scatter plot of parameters after some inferece
;; (independent short Markov chains)
[infer (plotf 'p0d1d (run (accumulate_dataset <%= smaller_sample_size %>
  (do reset_to_prior
      (mh default one 30)
      (collect a b)))))]
```

Elaboration: Model Selection
============================

[TODO Go through this]

```church'
clear
```

```church'
;; Prior on polynomial coefficients
[assume a (tag 'param 'a (normal 0 7))]
[assume b (tag 'param 'b (normal 0 4))]
[assume c (tag 'param 'c (normal 0 2))]

;; Prior probability of being a quadratic
[assume is_quadratic (tag 'model 0 (flip 0.5))]

;; Hypothesized relationship
[assume f
  (lambda (x)
    (if is_quadratic
        (+ a (* b x) (* c (* x x)))
        (+ a (* b x))))]

;; Prior for unknown noise level
[assume noise (tag 'hyper 'noise (gamma 1 1))]

;; Prior on the outlier rate
[assume outlier_prob (tag 'hyper 'outlier_prob (uniform_continuous 0.01 0.3))]

;; Per-point outlier check
[assume is_outlier (mem (lambda (i)
  (tag 'outlier i
   (flip outlier_prob))))]

;; Full data model: linear or quadratic relationship with additive
;; noise of unknown but consistent magnitude, plus outlier detection
;; with a broad Gaussian outlier model.
[assume obs_fun
  (lambda (i x)
    (if (is_outlier i)
        (normal 0 100)
        (normal (f x) noise)))]

[observe (obs_fun 0 1) 0.5]
[observe (obs_fun 1 4) 0]
[observe (obs_fun 2 -3) 1]
[observe (obs_fun 3 -5) -1]

;; Scatter plot of parameters after some inferece
;; (independent short Markov chains)
[infer (plotf 'p0d1d (run (accumulate_dataset <%= smaller_sample_size %>
  (do reset_to_prior
      (mh default one 30)
      (collect a b)))))]
```

[TODO illustrate and elaborate] Inference phenomenon: Bayes Occam's Razor
