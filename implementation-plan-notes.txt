Step 1: Block MH in Lite controlled by the stack
- Maintain {scope:block} in each node
  - Purely local syntactic scope specs for starters
- Data structure in trace: {(scope,block):set(node)}
  - adjust registerRandomChoice to maintain these
- Use scope specs from infer instructions to determine
  constructed scaffolds

Step 2: Test block MH in Lite

Step 3: Broaden scope specs to allow "one" and "all" everywhere
- and test

Probable step 4: port/implement other primitives
- Everything except pgibbs/scope/all is just something we have, over a
  scaffold with multiple principal nodes (which might be randomly
  selected)
- Do I need to deal with separating LKernels from MH somehow?
  - does not current detachAndRegen run all the latents too?  What
    about the AEKernels?
  - How do I run only the latents and not the other stuff?
- Vikash wants rejection sampling more than ordered pgibbs
  - (default/all first; then on a scaffold)
  - truly infinite bounds are contentful
- Vikash suggested pgibbs/scope/ordered, where we require all the border
  nodes to have ids in the scope and just do the thing cxx/pgibbs does
  on a border ordered by block id.

Further steps:
- Actually implement dynamic scope over traces, like the spec calls for
- Implement changeable block ids

In CXX:
- Maintain scope/block membership data in the nodes/trace
- Implement scaffold construction from blocks
- Actually implement dynamic scope over traces, like the spec calls for
- Implement changeable block ids

Is there right now a way to say how many particles pgibbs should use?
- Selsam says "hardcoded in inc/infer/pgibbs.h as the variable P".

Patch the spec:
- pgibbs should accept a count of repeats as well as particles
- meanfield maybe not, because it does not read the contents of the scaffold
  - though iterating (meanfield one) may make sense

More issues:
- How does this inference control language interact with continuous inference?
  - Obvious answer: start-continuous-inference accepts a control expression
    just like infer does, except that top-level repeat counts are pointless
